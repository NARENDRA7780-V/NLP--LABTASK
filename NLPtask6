import nltk
nltk.download('punkt_tab')
from nltk.util import ngrams
from nltk.lm import Laplace
from nltk.tokenize import word_tokenize
from nltk.lm.preprocessing import padded_everygram_pipeline

def ngram_smoothing(sentence, n):
    tokens = word_tokenize(sentence.lower())
    train_data, padded_sents = padded_everygram_pipeline(n, [tokens])
    model = Laplace(n) 
    model.fit(train_data, padded_sents)  
    return model

sentence = input("Enter a sentence: ")
n = int(input("Enter the value of N for N-grams: "))

model = ngram_smoothing(sentence, n)

tokens = word_tokenize(sentence.lower())
context = tokens[-n+1:] if n > 1 else []

next_words = [model.generate(text_seed=context) for _ in range(3)]
print("Next words:", ' '.join(next_words))
