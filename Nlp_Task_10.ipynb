{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ6AxR6ry8Dj5LvwiL5DzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NARENDRA7780-V/NLP--LABTASK/blob/main/Nlp_Task_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6MHoxY4gGDl",
        "outputId": "6f44a7e4-2249-49e9-da17-1ff8a8017898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['Web', 'example', 'web', 'page', 'text', 'parts', 'speech', 'example', 'cat', 'dog', 'verb', 'prepositions']\n",
            "Verbs: ['contains', 'jumps', 'contains']\n",
            "Adjectives: ['various', 'lazy']\n",
            "Entities: []\n"
          ]
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def pos_tag_and_extract_info(text):\n",
        "  doc = nlp(text)\n",
        "  nouns = []\n",
        "  verbs = []\n",
        "  adjectives = []\n",
        "  entities = []\n",
        "  for token in doc:\n",
        "    if token.pos_ == \"NOUN\":\n",
        "      nouns.append(token.text)\n",
        "    elif token.pos_ == \"VERB\":\n",
        "      verbs.append(token.text)\n",
        "    elif token.pos_ == \"ADJ\":\n",
        "      adjectives.append(token.text)\n",
        "    for entity in doc.ents:\n",
        "      entities.append((entity.text, entity.label_))\n",
        "  return nouns, verbs, adjectives, entities\n",
        "\n",
        "web_document = \"\"\"\n",
        "\n",
        "\n",
        "Example Web Page\n",
        "\n",
        "\n",
        "This is an example web page. It contains some text with various parts of speech.\n",
        "For example, \"The cat jumps over the lazy dog\" contains a noun, a verb, and prepositions.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "def extract_text_from_html(html):\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "  return soup.get_text()\n",
        "\n",
        "text_content = extract_text_from_html(web_document)\n",
        "nouns, verbs, adjectives, entities = pos_tag_and_extract_info(text_content)\n",
        "\n",
        "print(\"Nouns:\", nouns)\n",
        "print(\"Verbs:\", verbs)\n",
        "print(\"Adjectives:\", adjectives)\n",
        "print(\"Entities:\", entities)"
      ]
    }
  ]
}